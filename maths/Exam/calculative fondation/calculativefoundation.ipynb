{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57aa73f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from scipy.linalg import lu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a41af9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.8.0-cp313-cp313-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy>=1.24.1 in e:\\rnw\\parth\\lib\\site-packages (from scikit-learn) (2.2.6)\n",
      "Requirement already satisfied: scipy>=1.10.0 in e:\\rnw\\parth\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Collecting joblib>=1.3.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.3-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting threadpoolctl>=3.2.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.8.0-cp313-cp313-win_amd64.whl (8.0 MB)\n",
      "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/8.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/8.0 MB 1.4 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.0/8.0 MB 1.5 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.6/8.0 MB 1.7 MB/s eta 0:00:04\n",
      "   ---------- ----------------------------- 2.1/8.0 MB 1.9 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 2.6/8.0 MB 2.0 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 3.7/8.0 MB 2.3 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.2/8.0 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 5.0/8.0 MB 2.5 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 6.0/8.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.3/8.0 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.0/8.0 MB 3.2 MB/s  0:00:02\n",
      "Downloading joblib-1.5.3-py3-none-any.whl (309 kB)\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   ---------------------------------------- 3/3 [scikit-learn]\n",
      "\n",
      "Successfully installed joblib-1.5.3 scikit-learn-1.8.0 threadpoolctl-3.6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "! pip install  scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff721d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (500, 5)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\parth\\Downloads\\student_performance_500.csv\")\n",
    "\n",
    "subjects = df.columns[1:]\n",
    "X = df[subjects].values\n",
    "\n",
    "print(\"Dataset Shape:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b025d12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L1 Norm: 424.0\n",
      "L2 Norm: 190.45734430575263\n"
     ]
    }
   ],
   "source": [
    "v1 = X[0]\n",
    "v2 = X[1]\n",
    "\n",
    "norm1_L1 = np.linalg.norm(v1, 1)\n",
    "norm1_L2 = np.linalg.norm(v1, 2)\n",
    "\n",
    "print(\"\\nL1 Norm:\", norm1_L1)\n",
    "print(\"L2 Norm:\", norm1_L2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aea6a594",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dot Product: 30395\n",
      "Angle (degrees): 14.454035622037377\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dot_product = np.dot(v1, v2)\n",
    "angle = np.degrees(\n",
    "    np.arccos(dot_product / (np.linalg.norm(v1) * np.linalg.norm(v2)))\n",
    ")\n",
    "\n",
    "print(\"\\nDot Product:\", dot_product)\n",
    "print(\"Angle (degrees):\", angle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8423d2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cross Product (3 subjects): [ 2378 -1252 -1254]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cross_product = np.cross(v1[:3], v2[:3])\n",
    "print(\"\\nCross Product (3 subjects):\", cross_product)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f98ec2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Projection (first 5 values): [ 87.28728692  60.42966017 105.19237141  57.07245683  91.76355804]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "projection = (dot_product / np.dot(v2, v2)) * v2\n",
    "print(\"\\nProjection (first 5 values):\", projection[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701fa1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Covariance Matrix Shape: (5, 5)\n"
     ]
    }
   ],
   "source": [
    "X_T = X.T\n",
    "cov_matrix = np.cov(X, rowvar=False)\n",
    "print(\"\\nCovariance Matrix Shape:\", cov_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2affbe6d",
   "metadata": {},
   "source": [
    "## Line, Plane, and Hyperplane in the Context of the Student Performance Dataset\n",
    "\n",
    "In this dataset, each student is represented by a vector of subject scores.  \n",
    "If a student has scores in **n subjects**, then that student corresponds to a point in **n-dimensional space**.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Line (1D)\n",
    "\n",
    "A **line** exists in **one-dimensional space**.\n",
    "\n",
    "### In our dataset:\n",
    "- If we consider **only one subject** (e.g., Mathematics),\n",
    "- Each student has a single value (Math score).\n",
    "\n",
    "\\[\n",
    "\\mathbf{x} = [x]\n",
    "\\]\n",
    "\n",
    "All students lie along a **single line (number line)**.\n",
    "\n",
    "**Interpretation**:  \n",
    "Performance is compared using only **one criterion**.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Plane (2D)\n",
    "\n",
    "A **plane** exists in **two-dimensional space**.\n",
    "\n",
    "### In our dataset:\n",
    "- If we select **two subjects** (e.g., Mathematics and Physics),\n",
    "- Each student is represented as:\n",
    "\n",
    "\\[\n",
    "\\mathbf{x} = [x_1, x_2]\n",
    "\\]\n",
    "\n",
    "Each student becomes a **point on a 2D plane**.\n",
    "\n",
    "**Interpretation**:  \n",
    "We can visually compare students using a **scatter plot**, observing correlations between two subjects.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. 3D Space (3D)\n",
    "\n",
    "A **three-dimensional space** is defined by **three independent axes**.\n",
    "\n",
    "### In our dataset:\n",
    "- If we select **three subjects** (e.g., Math, Physics, Chemistry),\n",
    "- Each student is represented as:\n",
    "\n",
    "\\[\n",
    "\\mathbf{x} = [x_1, x_2, x_3]\n",
    "\\]\n",
    "\n",
    "Students now lie in a **3D coordinate space**.\n",
    "\n",
    "**Interpretation**:  \n",
    "Patterns in student performance become harder to visualize but capture **more information**.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Hyperplane (Higher Dimensions)\n",
    "\n",
    "A **hyperplane** is a generalization of a line and plane to **n dimensions**.\n",
    "\n",
    "### In our dataset:\n",
    "- With **n subjects**, each student is a point in **n-dimensional space**:\n",
    "\n",
    "\\[\n",
    "\\mathbf{x} = [x_1, x_2, \\dots, x_n]\n",
    "\\]\n",
    "\n",
    "- All students collectively form a cloud of points in an **n-dimensional hyperplane**.\n",
    "\n",
    "**Interpretation**:  \n",
    "Human visualization is no longer possible, but mathematical tools such as **PCA, LDA, and SVD** help analyze patterns.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Dimensionality Growth: 2D → 3D → nD\n",
    "\n",
    "| Number of Subjects | Dimension | Geometric Form |\n",
    "|-------------------|-----------|----------------|\n",
    "| 1 | 1D | Line |\n",
    "| 2 | 2D | Plane |\n",
    "| 3 | 3D | 3D Space |\n",
    "| n > 3 | nD | Hyperplane |\n",
    "\n",
    "As the number of subjects increases:\n",
    "- **Information captured increases**\n",
    "- **Visualization becomes difficult**\n",
    "- **Dimensionality reduction becomes essential**\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Why Hyperplanes Matter in This Dataset\n",
    "\n",
    "- Each student’s performance is a point in a high-dimensional hyperplane\n",
    "- **Decision boundaries in LDA** are hyperplanes separating “Above Average” and “Below Average” students\n",
    "- **PCA projects data from a high-dimensional hyperplane to a lower-dimensional plane (2D)**\n",
    "\n",
    "---\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "- A **line** models performance in one subject\n",
    "- A **plane** models performance in two subjects\n",
    "- A **hyperplane** models real-world student performance across many subjects\n",
    "- Increasing dimensionality provides richer information but requires linear algebra techniques to analyze effectively\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b46029a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Each student is a point in 5 dimensional space (hyperplane).\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEach student is a point in\", X.shape[1], \"dimensional space (hyperplane).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0f5d156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Eigenvalues:\n",
      "[249.55012843 228.13838326 212.90533937 194.81564332 198.83585632]\n"
     ]
    }
   ],
   "source": [
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "print(\"\\nTop 5 Eigenvalues:\")\n",
    "print(eigenvalues[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8c2c53d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LU Decomposition completed.\n",
      "L Shape: (5, 5)\n",
      "U Shape: (5, 5)\n"
     ]
    }
   ],
   "source": [
    "P, L, U = lu(cov_matrix)\n",
    "print(\"\\nLU Decomposition completed.\")\n",
    "print(\"L Shape:\", L.shape)\n",
    "print(\"U Shape:\", U.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0b045506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 3 Singular Values:\n",
      "[3781.91420073  342.2177717   326.33421191]\n"
     ]
    }
   ],
   "source": [
    "U_svd, S_svd, Vt_svd = np.linalg.svd(X, full_matrices=False)\n",
    "print(\"\\nTop 3 Singular Values:\")\n",
    "print(S_svd[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8572c229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PCA Explained Variance Ratio:\n",
      "[0.2301602  0.21041214]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "print(\"\\nPCA Explained Variance Ratio:\")\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6102dde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LDA completed. Reduced shape: (500, 1)\n"
     ]
    }
   ],
   "source": [
    "average_scores = X.mean(axis=1)\n",
    "labels = np.where(average_scores >= average_scores.mean(), 1, 0)\n",
    "lda = LDA(n_components=1)\n",
    "X_lda = lda.fit_transform(X, labels)\n",
    "print(\"\\nLDA completed. Reduced shape:\", X_lda.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34dddd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "parth (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
